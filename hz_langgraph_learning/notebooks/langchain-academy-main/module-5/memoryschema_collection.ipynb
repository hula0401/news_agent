{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot with Collection Schema \n",
    "\n",
    "## Review\n",
    "\n",
    "We extended our chatbot to save semantic memories to a single [user profile](https://langchain-ai.github.io/langgraph/concepts/memory/#profile). \n",
    "\n",
    "We also introduced a library, [Trustcall](https://github.com/hinthornw/trustcall), to update this schema with new information. \n",
    "\n",
    "## Goals\n",
    "\n",
    "Sometimes we want to save memories to a [collection](https://docs.google.com/presentation/d/181mvjlgsnxudQI6S3ritg9sooNyu4AcLLFH1UK0kIuk/edit#slide=id.g30eb3c8cf10_0_200) rather than single profile. \n",
    "\n",
    "Here we'll update our chatbot to [save memories to a collection](https://langchain-ai.github.io/langgraph/concepts/memory/#collection).\n",
    "\n",
    "We'll also show how to use [Trustcall](https://github.com/hinthornw/trustcall) to update this collection. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langchain_openai langgraph trustcall langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    # Check if the variable is set in the OS environment\n",
    "    env_value = os.environ.get(var)\n",
    "    if not env_value:\n",
    "        # If not set, prompt the user for input\n",
    "        env_value = getpass.getpass(f\"{var}: \")\n",
    "    \n",
    "    # Set the environment variable for the current process\n",
    "    os.environ[var] = env_value\n",
    "\n",
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langchain-academy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a collection schema\n",
    "\n",
    "Instead of storing user information in a fixed profile structure, we'll create a flexible collection schema to store memories about user interactions.\n",
    "\n",
    "Each memory will be stored as a separate entry with a single `content` field for the main information we want to remember\n",
    "\n",
    "This approach allows us to build an open-ended collection of memories that can grow and change as we learn more about the user.\n",
    "\n",
    "We can define a collection schema as a [Pydantic](https://docs.pydantic.dev/latest/) object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Memory(content='My name is Lance. I like to bike.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fixed version that handles ZhipuAI model's response format for MemoryCollection\n",
    "from pydantic import BaseModel, Field\n",
    "import json\n",
    "import re\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the model\n",
    "model = ChatOpenAI(\n",
    "    model=\"glm-4-flash\",\n",
    "    temperature=0,\n",
    "    api_key=os.environ[\"ZHIPUAI_API_KEY\"],\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    "    )\n",
    "\n",
    "# Create a more explicit prompt for structured output\n",
    "def create_memory_collection(user_input: str) -> MemoryCollection:\n",
    "    \"\"\"Extract memory collection information from user input\"\"\"\n",
    "    system_prompt = \"\"\"You are a helpful assistant that extracts memory information from conversations.\n",
    "    \n",
    "    Extract memories from the user input and return them as a JSON object with this structure:\n",
    "    {\n",
    "        \"memories\": [\n",
    "            {\n",
    "                \"content\": \"Description of the memory\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    Return ONLY a valid JSON object. If no memories are found, return an empty memories array.\"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=user_input)\n",
    "    ]\n",
    "    \n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Parse the JSON response\n",
    "    try:\n",
    "        # Try to extract JSON from the response\n",
    "        response_text = response.content.strip()\n",
    "        \n",
    "        # Look for JSON in the response\n",
    "        if response_text.startswith('{') and response_text.endswith('}'):\n",
    "            memory_data = json.loads(response_text)\n",
    "        else:\n",
    "            # Try to find JSON within the response\n",
    "            json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
    "            if json_match:\n",
    "                memory_data = json.loads(json_match.group())\n",
    "            else:\n",
    "                # Fallback: create an empty memory collection\n",
    "                memory_data = {\n",
    "                    \"memories\": []\n",
    "                }\n",
    "        \n",
    "        return MemoryCollection(**memory_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing response: {e}\")\n",
    "        print(f\"Response was: {response.content}\")\n",
    "        # Return an empty memory collection\n",
    "        return MemoryCollection(memories=[])\n",
    "\n",
    "# Test the function\n",
    "memory_collection = create_memory_collection(\"My name is Lance. I like to bike.\")\n",
    "memory_collection.memories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted memories:\n",
      "1. Biking around San Francisco and visiting bakeries.\n",
      "2. Enjoying reading science fiction books.\n"
     ]
    }
   ],
   "source": [
    "# Test with more complex input\n",
    "memory_collection = create_memory_collection(\"My name is Lance. I like to bike around San Francisco and visit bakeries. I also enjoy reading science fiction books.\")\n",
    "print(\"Extracted memories:\")\n",
    "for i, memory in enumerate(memory_collection.memories):\n",
    "    print(f\"{i+1}. {memory.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Memory(BaseModel):\n",
    "    content: str = Field(description=\"The main content of the memory. For example: User expressed interest in learning about French.\")\n",
    "\n",
    "class MemoryCollection(BaseModel):\n",
    "    memories: list[Memory] = Field(description=\"A list of memories about the user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"ZHIPUAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can used LangChain's chat model [chat model](https://python.langchain.com/docs/concepts/chat_models/) interface's [`with_structured_output`](https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage) method to enforce structured output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutputParserException",
     "evalue": "Failed to parse MemoryCollection from completion {\"answer\": \"Nice to meet you Lance! Biking is a great hobby.\"}. Got: 1 validation error for MemoryCollection\nmemories\n  Field required [type=missing, input_value={'answer': 'Nice to meet ...king is a great hobby.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/missing\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Agents/News_agent/.venv/lib/python3.13/site-packages/langchain_core/output_parsers/pydantic.py:28\u001b[39m, in \u001b[36mPydanticOutputParser._parse_obj\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mself\u001b[39m.pydantic_object, pydantic.BaseModel):\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpydantic_object\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mself\u001b[39m.pydantic_object, pydantic.v1.BaseModel):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Agents/News_agent/.venv/lib/python3.13/site-packages/pydantic/main.py:716\u001b[39m, in \u001b[36mBaseModel.model_validate\u001b[39m\u001b[34m(cls, obj, strict, extra, from_attributes, context, by_alias, by_name)\u001b[39m\n\u001b[32m    711\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[32m    712\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mAt least one of `by_alias` or `by_name` must be set to True.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    713\u001b[39m         code=\u001b[33m'\u001b[39m\u001b[33mvalidate-by-alias-and-name-false\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    714\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m716\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextra\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m    \u001b[49m\u001b[43mby_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for MemoryCollection\nmemories\n  Field required [type=missing, input_value={'answer': 'Nice to meet ...king is a great hobby.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/missing",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOutputParserException\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m model_with_structure = model.with_structured_output(MemoryCollection, method=\u001b[33m\"\u001b[39m\u001b[33mjson_mode\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Invoke the model to produce structured output that matches the schema\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m memory_collection = \u001b[43mmodel_with_structure\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMy name is Lance. I like to bike.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m memory_collection.memories\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Agents/News_agent/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:3246\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3244\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3245\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3246\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3247\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3248\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Agents/News_agent/.venv/lib/python3.13/site-packages/langchain_core/output_parsers/base.py:200\u001b[39m, in \u001b[36mBaseOutputParser.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    194\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    197\u001b[39m     **kwargs: Any,\n\u001b[32m    198\u001b[39m ) -> T:\n\u001b[32m    199\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_with_config(\n\u001b[32m    209\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m.parse_result([Generation(text=inner_input)]),\n\u001b[32m    210\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    211\u001b[39m         config,\n\u001b[32m    212\u001b[39m         run_type=\u001b[33m\"\u001b[39m\u001b[33mparser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    213\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Agents/News_agent/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:2092\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   2088\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   2089\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   2090\u001b[39m         output = cast(\n\u001b[32m   2091\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m2092\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2093\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   2094\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2095\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2096\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2097\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2098\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2099\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   2100\u001b[39m         )\n\u001b[32m   2101\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2102\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Agents/News_agent/.venv/lib/python3.13/site-packages/langchain_core/runnables/config.py:430\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    429\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Agents/News_agent/.venv/lib/python3.13/site-packages/langchain_core/output_parsers/base.py:201\u001b[39m, in \u001b[36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[39m\u001b[34m(inner_input)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    194\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    197\u001b[39m     **kwargs: Any,\n\u001b[32m    198\u001b[39m ) -> T:\n\u001b[32m    199\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[32m    200\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_with_config(\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    204\u001b[39m             \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    205\u001b[39m             config,\n\u001b[32m    206\u001b[39m             run_type=\u001b[33m\"\u001b[39m\u001b[33mparser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    207\u001b[39m         )\n\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_with_config(\n\u001b[32m    209\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m.parse_result([Generation(text=inner_input)]),\n\u001b[32m    210\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    211\u001b[39m         config,\n\u001b[32m    212\u001b[39m         run_type=\u001b[33m\"\u001b[39m\u001b[33mparser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    213\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Agents/News_agent/.venv/lib/python3.13/site-packages/langchain_core/output_parsers/pydantic.py:66\u001b[39m, in \u001b[36mPydanticOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     65\u001b[39m     json_object = \u001b[38;5;28msuper\u001b[39m().parse_result(result)\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_object\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException:\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m partial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Agents/News_agent/.venv/lib/python3.13/site-packages/langchain_core/output_parsers/pydantic.py:35\u001b[39m, in \u001b[36mPydanticOutputParser._parse_obj\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(msg)\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (pydantic.ValidationError, pydantic.v1.ValidationError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._parser_exception(e, obj) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mOutputParserException\u001b[39m: Failed to parse MemoryCollection from completion {\"answer\": \"Nice to meet you Lance! Biking is a great hobby.\"}. Got: 1 validation error for MemoryCollection\nmemories\n  Field required [type=missing, input_value={'answer': 'Nice to meet ...king is a great hobby.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/missing\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE "
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the model\n",
    "model = ChatOpenAI(\n",
    "    model=\"glm-4.5-flash\",\n",
    "    temperature=0,\n",
    "    api_key=os.environ[\"ZHIPUAI_API_KEY\"],\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    "    )\n",
    "\n",
    "# Bind schema to model\n",
    "model_with_structure = model.with_structured_output(MemoryCollection, method=\"json_mode\")\n",
    "\n",
    "# Invoke the model to produce structured output that matches the schema\n",
    "memory_collection = model_with_structure.invoke([HumanMessage(\"My name is Lance. I like to bike.\")])\n",
    "memory_collection.memories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `model_dump()` to serialize a Pydantic model instance into a Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'Biking around San Francisco and visiting bakeries.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_collection.memories[0].model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save dictionary representation of each memory to the store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "# Initialize the in-memory store\n",
    "in_memory_store = InMemoryStore()\n",
    "\n",
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "namespace_for_memory = (user_id, \"memories\")\n",
    "\n",
    "# Save a memory to namespace as key and value\n",
    "key = str(uuid.uuid4())\n",
    "value = memory_collection.memories[0].model_dump()\n",
    "in_memory_store.put(namespace_for_memory, key, value)\n",
    "\n",
    "key = str(uuid.uuid4())\n",
    "value = memory_collection.memories[1].model_dump()\n",
    "in_memory_store.put(namespace_for_memory, key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for memories in the store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'namespace': ['1', 'memories'], 'key': '345e8f74-c3c6-4b70-9fe6-7b218ffda40f', 'value': {'content': 'Biking around San Francisco and visiting bakeries.'}, 'created_at': '2025-10-23T04:41:09.765066+00:00', 'updated_at': '2025-10-23T04:41:09.765069+00:00', 'score': None}\n",
      "{'namespace': ['1', 'memories'], 'key': '21b707a8-629a-4e66-9fe6-9ffe14ad3c90', 'value': {'content': 'Enjoying reading science fiction books.'}, 'created_at': '2025-10-23T04:41:09.765123+00:00', 'updated_at': '2025-10-23T04:41:09.765124+00:00', 'score': None}\n"
     ]
    }
   ],
   "source": [
    "# Search \n",
    "for m in in_memory_store.search(namespace_for_memory):\n",
    "    print(m.dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating collection schema\n",
    "\n",
    "We discussed the challenges with updating a profile schema in the last lesson. \n",
    "\n",
    "The same applies for collections! \n",
    "\n",
    "We want the ability to update the collection with new memories as well as update existing memories in the collection. \n",
    "\n",
    "Now we'll show that [Trustcall](https://github.com/hinthornw/trustcall) can be also used to update a collection. \n",
    "\n",
    "This enables both addition of new memories as well as [updating existing memories in the collection](https://github.com/hinthornw/trustcall?tab=readme-ov-file#simultanous-updates--insertions\n",
    ").\n",
    "\n",
    "Let's define a new extractor with Trustcall. \n",
    "\n",
    "As before, we provide the schema for each memory, `Memory`.  \n",
    "\n",
    "But, we can supply `enable_inserts=True` to allow the extractor to insert new memories to the collection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustcall import create_extractor\n",
    "\n",
    "# Create the extractor\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Memory],\n",
    "    tool_choice=\"Memory\",\n",
    "    enable_inserts=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# Instruction\n",
    "instruction = \"\"\"Extract memories from the following conversation:\"\"\"\n",
    "\n",
    "# Conversation\n",
    "conversation = [HumanMessage(content=\"Hi, I'm Lance.\"), \n",
    "                AIMessage(content=\"Nice to meet you, Lance.\"), \n",
    "                HumanMessage(content=\"This morning I had a nice bike ride in San Francisco.\")]\n",
    "\n",
    "# Invoke the extractor\n",
    "result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=instruction)] + conversation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_-8226109009940481432)\n",
      " Call ID: call_-8226109009940481432\n",
      "  Args:\n",
      "    content: User's name is Lance\n",
      "  Memory (call_-8226109009940481431)\n",
      " Call ID: call_-8226109009940481431\n",
      "  Args:\n",
      "    content: Lance had a nice bike ride in San Francisco this morning\n"
     ]
    }
   ],
   "source": [
    "# Messages contain the tool calls\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"User's name is Lance\"\n",
      "content='Lance had a nice bike ride in San Francisco this morning'\n"
     ]
    }
   ],
   "source": [
    "# Responses contain the memories that adhere to the schema\n",
    "for m in result[\"responses\"]: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'call_-8226109009940481432'}\n",
      "{'id': 'call_-8226109009940481431'}\n"
     ]
    }
   ],
   "source": [
    "# Metadata contains the tool call  \n",
    "for m in result[\"response_metadata\"]: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', 'Memory', {'content': \"User's name is Lance\"}),\n",
       " ('1',\n",
       "  'Memory',\n",
       "  {'content': 'Lance had a nice bike ride in San Francisco this morning'})]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the conversation\n",
    "updated_conversation = [AIMessage(content=\"That's great, did you do after?\"), \n",
    "                        HumanMessage(content=\"I went to Tartine and ate a croissant.\"),                        \n",
    "                        AIMessage(content=\"What else is on your mind?\"),\n",
    "                        HumanMessage(content=\"I was thinking about my Japan, and going back this winter!\"),]\n",
    "\n",
    "# Update the instruction\n",
    "system_msg = \"\"\"Update existing memories and create new ones based on the following conversation:\"\"\"\n",
    "\n",
    "# We'll save existing memories, giving them an ID, key (tool name), and value\n",
    "tool_name = \"Memory\"\n",
    "existing_memories = [(str(i), tool_name, memory.model_dump()) for i, memory in enumerate(result[\"responses\"])] if result[\"responses\"] else None\n",
    "existing_memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the extractor with our updated conversation and existing memories\n",
    "result = trustcall_extractor.invoke({\"messages\": updated_conversation, \n",
    "                                     \"existing\": existing_memories})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_-8226176423748736206)\n",
      " Call ID: call_-8226176423748736206\n",
      "  Args:\n",
      "    content: User went to Tartine and ate a croissant\n"
     ]
    }
   ],
   "source": [
    "# Messages from the model indicate two tool calls were made\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='User went to Tartine and ate a croissant'\n"
     ]
    }
   ],
   "source": [
    "# Responses contain the memories that adhere to the schema\n",
    "for m in result[\"responses\"]: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that we updated the first memory in the collection by specifying the `json_doc_id`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'call_-8226176423748736206'}\n"
     ]
    }
   ],
   "source": [
    "# Metadata contains the tool call  \n",
    "for m in result[\"response_metadata\"]: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangSmith trace: \n",
    "\n",
    "https://smith.langchain.com/public/ebc1cb01-f021-4794-80c0-c75d6ea90446/r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot with collection schema updating\n",
    "\n",
    "Now, let's bring Trustcall into our chatbot to create and update a memory collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "import uuid\n",
    "\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langchain_core.messages import merge_message_runs\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.store.base import BaseStore\n",
    "\n",
    "# Initialize the model\n",
    "model = ChatOpenAI(\n",
    "    model=\"glm-4.5-flash\",\n",
    "    temperature=0,\n",
    "    api_key=os.environ[\"ZHIPUAI_API_KEY\"],\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    "    )\n",
    "\n",
    "# Memory schema\n",
    "class Memory(BaseModel):\n",
    "    content: str = Field(description=\"The main content of the memory. For example: User expressed interest in learning about French.\")\n",
    "\n",
    "# Create the Trustcall extractor\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Memory],\n",
    "    tool_choice=\"Memory\",\n",
    "    # This allows the extractor to insert new memories\n",
    "    enable_inserts=True,\n",
    ")\n",
    "\n",
    "# Chatbot instruction\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful chatbot. You are designed to be a companion to a user. \n",
    "\n",
    "You have a long term memory which keeps track of information you learn about the user over time.\n",
    "\n",
    "Current Memory (may include updated memories from this conversation): \n",
    "\n",
    "{memory}\"\"\"\n",
    "\n",
    "# Trustcall instruction\n",
    "TRUSTCALL_INSTRUCTION = \"\"\"Reflect on following interaction. \n",
    "\n",
    "Use the provided tools to retain any necessary memories about the user. \n",
    "\n",
    "Use parallel tool calling to handle updates and insertions simultaneously:\"\"\"\n",
    "\n",
    "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Load memories from the store and use them to personalize the chatbot's response.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve memory from the store\n",
    "    namespace = (\"memories\", user_id)\n",
    "    memories = store.search(namespace)\n",
    "\n",
    "    # Format the memories for the system prompt\n",
    "    info = \"\\n\".join(f\"- {mem.value['content']}\" for mem in memories)\n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=info)\n",
    "\n",
    "    # Respond using memory as well as the chat history\n",
    "    response = model.invoke([SystemMessage(content=system_msg)]+state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Reflect on the chat history and update the memory collection.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Define the namespace for the memories\n",
    "    namespace = (\"memories\", user_id)\n",
    "\n",
    "    # Retrieve the most recent memories for context\n",
    "    existing_items = store.search(namespace)\n",
    "\n",
    "    # Format the existing memories for the Trustcall extractor\n",
    "    tool_name = \"Memory\"\n",
    "    existing_memories = ([(existing_item.key, tool_name, existing_item.value)\n",
    "                          for existing_item in existing_items]\n",
    "                          if existing_items\n",
    "                          else None\n",
    "                        )\n",
    "\n",
    "    # Merge the chat history and the instruction\n",
    "    updated_messages=list(merge_message_runs(messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION)] + state[\"messages\"]))\n",
    "\n",
    "    # Invoke the extractor\n",
    "    result = trustcall_extractor.invoke({\"messages\": updated_messages, \n",
    "                                        \"existing\": existing_memories})\n",
    "\n",
    "    # Save the memories from Trustcall to the store\n",
    "    for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
    "        store.put(namespace,\n",
    "                  rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
    "                  r.model_dump(mode=\"json\"),\n",
    "            )\n",
    "\n",
    "# Define the graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_node(\"write_memory\", write_memory)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_edge(\"call_model\", \"write_memory\")\n",
    "builder.add_edge(\"write_memory\", END)\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# Compile the graph with the checkpointer fir and store\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Lance! I remember you introduced yourself earlier. It's nice to meet you again! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"Hi, my name is Lance\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I like to bike around San Francisco\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That sounds like a lot of fun! San Francisco has some beautiful routes for biking. Do you have a favorite trail or area you like to explore?\n"
     ]
    }
   ],
   "source": [
    "# User input \n",
    "input_messages = [HumanMessage(content=\"I like to bike around San Francisco\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': {'content': \"User's name is Lance.\"}, 'key': 'dee65880-dd7d-4184-8ca1-1f7400f7596b', 'namespace': ['memories', '1'], 'created_at': '2024-10-30T22:18:52.413283+00:00', 'updated_at': '2024-10-30T22:18:52.413284+00:00'}\n",
      "{'value': {'content': 'User likes to bike around San Francisco.'}, 'key': '662195fc-8ea4-4f64-a6b6-6b86d9cb85c0', 'namespace': ['memories', '1'], 'created_at': '2024-10-30T22:18:56.597813+00:00', 'updated_at': '2024-10-30T22:18:56.597814+00:00'}\n"
     ]
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "namespace = (\"memories\", user_id)\n",
    "memories = across_thread_memory.search(namespace)\n",
    "for m in memories:\n",
    "    print(m.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I also enjoy going to bakeries\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Biking and bakeries make a great combination! Do you have a favorite bakery in San Francisco, or are you on the hunt for new ones to try?\n"
     ]
    }
   ],
   "source": [
    "# User input \n",
    "input_messages = [HumanMessage(content=\"I also enjoy going to bakeries\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue the conversation in a new thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What bakeries do you recommend for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Since you enjoy biking around San Francisco, you might like to check out some of these bakeries that are both delicious and located in areas that are great for a bike ride:\n",
      "\n",
      "1. **Tartine Bakery** - Located in the Mission District, it's famous for its bread and pastries. The area is vibrant and perfect for a leisurely ride.\n",
      "\n",
      "2. **Arsicault Bakery** - Known for its incredible croissants, it's in the Richmond District, which offers a nice ride through Golden Gate Park.\n",
      "\n",
      "3. **B. Patisserie** - Situated in Lower Pacific Heights, this bakery is renowned for its kouign-amann and other French pastries. The neighborhood is charming and bike-friendly.\n",
      "\n",
      "4. **Mr. Holmes Bakehouse** - Famous for its cruffins, it's located in the Tenderloin, which is a bit more urban but still accessible by bike.\n",
      "\n",
      "5. **Noe Valley Bakery** - A cozy spot in Noe Valley, perfect for a stop after exploring the hilly streets of the area.\n",
      "\n",
      "Do any of these sound like a good fit for your next biking adventure?\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"What bakeries do you recommend for me?\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangSmith \n",
    "\n",
    "https://smith.langchain.com/public/c87543ec-b426-4a82-a3ab-94d01c01d9f4/r\n",
    "\n",
    "## Studio\n",
    "\n",
    "![Screenshot 2024-10-30 at 11.29.25 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/6732d0876d3daa19fef993ba_Screenshot%202024-11-11%20at%207.50.21%E2%80%AFPM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
