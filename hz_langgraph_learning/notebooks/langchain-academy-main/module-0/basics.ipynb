{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "660ce795-9307-4c2c-98a1-beabcb36c740",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-0/basics.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/56295530-getting-set-up-video-guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef597741-3211-4ecc-92f7-f58023ee237e",
   "metadata": {},
   "source": [
    "# LangChain Academy\n",
    "\n",
    "Welcome to LangChain Academy! \n",
    "\n",
    "## Context\n",
    "\n",
    "At LangChain, we aim to make it easy to build LLM applications. One type of LLM application you can build is an agent. There‚Äôs a lot of excitement around building agents because they can automate a wide range of tasks that were previously impossible. \n",
    "\n",
    "In practice though, it is incredibly difficult to build systems that reliably execute on these tasks. As we‚Äôve worked with our users to put agents into production, we‚Äôve learned that more control is often necessary. You might need an agent to always call a specific tool first or use different prompts based on its state. \n",
    "\n",
    "To tackle this problem, we‚Äôve built [LangGraph](https://langchain-ai.github.io/langgraph/) ‚Äî a framework for building agent and multi-agent applications. Separate from the LangChain package, LangGraph‚Äôs core design philosophy is to help developers add better precision and control into agent workflows, suitable for the complexity of real-world systems.\n",
    "\n",
    "## Course Structure\n",
    "\n",
    "The course is structured as a set of modules, with each module focused on a particular theme related to LangGraph. You will see a folder for each module, which contains a series of notebooks. A video will accompany each notebook to help walk through the concepts, but the notebooks are also stand-alone, meaning that they contain explanations and can be viewed independently of the videos. Each module folder also contains a `studio` folder, which contains a set of graphs that can be loaded into [LangGraph Studio](https://github.com/langchain-ai/langgraph-studio), our IDE for building LangGraph applications.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Before you begin, please follow the instructions in the `README` to create an environment and install dependencies.\n",
    "\n",
    "## Chat models\n",
    "\n",
    "In this course, we'll be using [Chat Models](https://python.langchain.com/v0.2/docs/concepts/#chat-models), which do a few things take a sequence of messages as inputs and return chat messages as outputs. LangChain does not host any Chat Models, rather we rely on third party integrations. [Here](https://python.langchain.com/v0.2/docs/integrations/chat/) is a list of 3rd party chat model integrations within LangChain! By default, the course will use [ChatOpenAI](https://python.langchain.com/v0.2/docs/integrations/chat/openai/) because it is both popular and performant. As noted, please ensure that you have an `OPENAI_API_KEY`.\n",
    "\n",
    "Let's check that your `OPENAI_API_KEY` is set and, if not, you will be asked to enter it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f9a52c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/haozhezhang/Documents/Agents/News_agent/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "  File \"/var/folders/rd/wvk7c0712r5czjzzfb1mh5b40000gn/T/ipykernel_5858/2766978719.py\", line 1, in <module>\n",
      "    get_ipython().run_line_magic('pip', 'install --quiet -U langchain_openai langchain_core langchain_community langchain-tavily')\n",
      "  File \"/Users/haozhezhang/Documents/Agents/News_agent/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2482, in run_line_magic\n",
      "  File \"/Users/haozhezhang/Documents/Agents/News_agent/.venv/lib/python3.10/site-packages/IPython/core/magics/packaging.py\", line 105, in pip\n",
      "  File \"/Users/haozhezhang/Documents/Agents/News_agent/.venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 740, in system_piped\n",
      "  File \"/Users/haozhezhang/Documents/Agents/News_agent/.venv/lib/python3.10/site-packages/IPython/utils/_process_posix.py\", line 125, in system\n",
      "ModuleNotFoundError: No module named 'pexpect'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/haozhezhang/Documents/Agents/News_agent/.venv/lib/python3.10/site-packages/pygments/styles/__init__.py\", line 45, in get_style_by_name\n",
      "ModuleNotFoundError: No module named 'pygments.styles.default'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/haozhezhang/Documents/Agents/News_agent/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2170, in showtraceback\n",
      "  File \"/Users/haozhezhang/Documents/Agents/News_agent/.venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1457, in structured_traceback\n",
      "  File \"/Users/haozhezhang/Documents/Agents/News_agent/.venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1348, in structured_traceback\n",
      "  File \"/Users/haozhezhang/Documents/Agents/News_agent/.venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1195, in structured_traceback\n",
      "  File \"/Users/haozhezhang/Documents/Agents/News_agent/.venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1085, in format_exception_as_a_whole\n",
      "  File \"/Users/haozhezhang/Documents/Agents/News_agent/.venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1136, in get_records\n",
      "  File \"/Users/haozhezhang/Documents/Agents/News_agent/.venv/lib/python3.10/site-packages/pygments/styles/__init__.py\", line 47, in get_style_by_name\n",
      "pygments.util.ClassNotFound: Could not find style module 'pygments.styles.default', though it should be builtin.\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langchain_community langchain-tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2a15227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"ZHIPUAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a326f35b",
   "metadata": {},
   "source": [
    "[Here](https://python.langchain.com/v0.2/docs/how_to/#chat-models) is a useful how-to for all the things that you can do with chat models, but we'll show a few highlights below. If you've run `pip install -r requirements.txt` as noted in the README, then you've installed the `langchain-openai` package. With this, we can instantiate our `ChatOpenAI` model object. If you are signing up for the API for the first time, you should receive [free credits](https://community.openai.com/t/understanding-api-limits-and-free-tier/498517) that can be applied to any of the models. You can see pricing for various models [here](https://openai.com/api/pricing/). The notebooks will default to `gpt-4o` because it's a good balance of quality, price, and speed [see more here](https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4-gpt-4-turbo-gpt-4o-and-gpt-4o-mini), but you can also opt for the lower priced `gpt-3.5` series models. \n",
    "\n",
    "There are [a few standard parameters](https://python.langchain.com/v0.2/docs/concepts/#chat-models) that we can set with chat models. Two of the most common are:\n",
    "\n",
    "* `model`: the name of the model\n",
    "* `temperature`: the sampling temperature\n",
    "\n",
    "`Temperature` controls the randomness or creativity of the model's output where low temperature (close to 0) is more deterministic and focused outputs. This is good for tasks requiring accuracy or factual responses. High temperature (close to 1) is good for creative tasks or generating varied responses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e19a54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "glm4p5_chat = ChatOpenAI(\n",
    "    model=\"glm-4.5-flash\",\n",
    "    temperature=0,\n",
    "    api_key=os.environ[\"ZHIPUAI_API_KEY\"],\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    "    )\n",
    "glm4_chat = ChatOpenAI(\n",
    "    model=\"glm-4-flash\",\n",
    "    temperature=0,\n",
    "    api_key=os.environ[\"ZHIPUAI_API_KEY\"],\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28450d1b",
   "metadata": {},
   "source": [
    "Chat models in LangChain have a number of [default methods](https://python.langchain.com/v0.2/docs/concepts/#runnable-interface). For the most part, we'll be using:\n",
    "\n",
    "* `stream`: stream back chunks of the response\n",
    "* `invoke`: call the chain on an input\n",
    "\n",
    "And, as mentioned, chat models take [messages](https://python.langchain.com/v0.2/docs/concepts/#messages) as input. Messages have a role (that describes who is saying the message) and a content property. We'll be talking a lot more about this later, but here let's just show the basics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1280e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Here\\'s a simple \"Hello, World!\" program in Python:\\n\\n```python\\nprint(\"Hello, World!\")\\n```\\n\\n### Explanation:\\n1. **`print()`**: This is a built-in Python function that outputs text to the console.\\n2. **`\"Hello, World!\"`**: This is a string (text) enclosed in double quotes. The content inside the quotes is displayed exactly as written.\\n\\n### How to Run:\\n1. Save the code in a file named `hello.py`.\\n2. Open a terminal/command prompt.\\n3. Navigate to the directory where you saved the file.\\n4. Run the command:  \\n   ```bash\\n   python hello.py\\n   ```\\n5. You\\'ll see the output:  \\n   ```\\n   Hello, World!\\n   ```\\n\\n### Key Notes:\\n- Python is case-sensitive, so `print` must be lowercase.\\n- The quotes can be single (`\\'`) or double (`\"`), but they must match.\\n- This program works in all Python versions (2.x and 3.x), though Python 3.x is recommended.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 302, 'prompt_tokens': 7, 'total_tokens': 309, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 4}}, 'model_name': 'glm-4.5-flash', 'system_fingerprint': None, 'id': '20251023150729b3cb2170d749463a', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--6165a191-2a71-4187-b104-fc231fe8f169-0', usage_metadata={'input_tokens': 7, 'output_tokens': 302, 'total_tokens': 309, 'input_token_details': {'cache_read': 4}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Create a message\n",
    "msg = HumanMessage(content=\"Hello world\", name=\"Lance\")\n",
    "\n",
    "# Message list\n",
    "messages = [msg]\n",
    "\n",
    "# Invoke the model with a list of messages \n",
    "glm4p5_chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac73e4c",
   "metadata": {},
   "source": [
    "We get an `AIMessage` response. Also, note that we can just invoke a chat model with a string. When a string is passed in as input, it is converted to a `HumanMessage` and then passed to the underlying model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27c6c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Here\\'s a simple \"Hello, World!\" program in Python:\\n\\n```python\\nprint(\"Hello, World!\")\\n```\\n\\n### Explanation:\\n1. `print()` is a built-in Python function that outputs text to the console.\\n2. `\"Hello, World!\"` is a string literal (text enclosed in quotes) that gets printed.\\n\\n### How to run it:\\n1. Save the code in a file named `hello.py`\\n2. Run it using Python:\\n   ```bash\\n   python hello.py\\n   ```\\n\\n### Output:\\n```\\nHello, World!\\n```\\n\\n### Alternative versions in other languages:\\n\\n**JavaScript:**\\n```javascript\\nconsole.log(\"Hello, World!\");\\n```\\n\\n**Java:**\\n```java\\npublic class HelloWorld {\\n    public static void main(String[] args) {\\n        System.out.println(\"Hello, World!\");\\n    }\\n}\\n```\\n\\n**C++:**\\n```cpp\\n#include <iostream>\\nint main() {\\n    std::cout << \"Hello, World!\" << std::endl;\\n    return 0;\\n}\\n```\\n\\n**C#:**\\n```csharp\\nusing System;\\nclass Program {\\n    static void Main() {\\n        Console.WriteLine(\"Hello, World!\");\\n    }\\n}\\n```\\n\\nThe Python version is the most concise for this simple task! üêç', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 312, 'prompt_tokens': 7, 'total_tokens': 319, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 4}}, 'model_name': 'glm-4.5-flash', 'system_fingerprint': None, 'id': '2025102113375287c8b4decf0e4c89', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--a966fbbe-9939-4373-b584-062d9082c82e-0', usage_metadata={'input_tokens': 7, 'output_tokens': 312, 'total_tokens': 319, 'input_token_details': {'cache_read': 4}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "glm4p5_chat.invoke(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc2f0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello üëã! I'm ChatGLM, the artificial intelligence assistant, nice to meet you. How can I help you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 7, 'total_tokens': 36, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'glm-4-flash', 'system_fingerprint': None, 'id': '20251021133842730225fa2c454546', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--3fefadc2-60cb-4707-9ee4-b77c66efbb82-0', usage_metadata={'input_tokens': 7, 'output_tokens': 29, 'total_tokens': 36, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "glm4_chat.invoke(\"hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582c0e5a",
   "metadata": {},
   "source": [
    "The interface is consistent across all chat models and models are typically initialized once at the start up each notebooks. \n",
    "\n",
    "So, you can easily switch between models without changing the downstream code if you have strong preference for another provider.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0069a",
   "metadata": {},
   "source": [
    "## Search Tools\n",
    "\n",
    "You'll also see [Tavily](https://tavily.com/) in the README, which is a search engine optimized for LLMs and RAG, aimed at efficient, quick, and persistent search results. As mentioned, it's easy to sign up and offers a generous free tier. Some lessons (in Module 4) will use Tavily by default but, of course, other search tools can be used if you want to modify the code for yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091dff13",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "_set_env(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d69da9",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from langchain_tavily import TavilySearch  # updated at 1.0\n",
    "\n",
    "tavily_search = TavilySearch(max_results=3)\n",
    "\n",
    "data = tavily_search.invoke({\"query\": \"AAPL NEWS?\"})\n",
    "search_docs = data.get(\"results\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06f87e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.cnn.com/markets/stocks/AAPL',\n",
       "  'title': 'AAPL Stock Quote Price and Forecast - CNN',\n",
       "  'content': '[Markets](https://www.cnn.com/markets) [More](https://www.cnn.com/markets/stocks/AAPL) *   [Sign out](https://www.cnn.com/markets/stocks/AAPL#) *   [Sign out](https://www.cnn.com/markets/stocks/AAPL#) [Quote](https://www.cnn.com/markets/stocks/AAPL#quote \"Quote\") [About](https://www.cnn.com/markets/stocks/AAPL#about \"About\") [News](https://www.cnn.com/markets/stocks/AAPL#news \"News\") [Financials](https://www.cnn.com/markets/stocks/AAPL#financials \"Financials\") [Competitors](https://www.cnn.com/markets/stocks/AAPL#competitors \"Competitors\") [Yesterday 6:42am ET Apple (AAPL) Sees Strongest iPhone Growth Since the Pandemic by TipRanks](https://www.tipranks.com/news/apple-aapl-sees-strongest-iphone-growth-since-the-pandemic?utm_source=edition.cnn.com&utm_medium=referral)[Oct 18, 2025 11:02pm ET TRB Advisors LP Reduces Stake in Apple Inc by TipRanks](https://www.tipranks.com/news/company-announcements/trb-advisors-lp-reduces-stake-in-apple-inc-2?utm_source=edition.cnn.com&utm_medium=referral)[Oct 18, 2025 11:01pm ET Manitou Investment Management Ltd. Reduces Apple Inc. Stake by TipRanks](https://www.tipranks.com/news/company-announcements/manitou-investment-management-ltd-reduces-apple-inc-stake?utm_source=edition.cnn.com&utm_medium=referral)[Oct 18, 2025 11:01am ET Apple‚Äôs Bold Moves: iPhone Air Success & F1 Deal by TipRanks](https://www.tipranks.com/news/weekend-updates/apples-bold-moves-iphone-air-success-f1-deal?utm_source=edition.cnn.com&utm_medium=referral)[Oct 17, 2025 1:30pm ET Apple‚Äôs (AAPL) New iPhone Air Sold Out within Minutes of Launching in China by TipRanks](https://www.tipranks.com/news/apples-aapl-new-iphone-air-sold-out-within-minutes-of-launching-in-china?utm_source=edition.cnn.com&utm_medium=referral)[Oct 17, 2025 12:15pm ET Midday Fly By: Apple new F1 broadcast partner, CSX reports Q3 beat by TipRanks](https://www.tipranks.com/news/the-fly/midday-fly-by-apple-new-f1-broadcast-partner-csx-reports-q[...]------ [AAPL](https://www.cnn.com/markets/stocks/AAPL) *   [Sign out](https://www.cnn.com/markets/stocks/AAPL#) *   [Sign out](https://www.cnn.com/markets/stocks/AAPL#) [Agree](https://www.cnn.com/markets/stocks/AAPL#)',\n",
       "  'score': 0.81204927,\n",
       "  'raw_content': None},\n",
       " {'url': 'https://www.google.com/finance/beta/quote/AAPL:NASDAQ',\n",
       "  'title': 'Apple Inc (AAPL) Stock Price & News - Google Finance',\n",
       "  'content': '[_manage\\\\_search_ Market trends](https://www.google.com/finance/beta/quote/markets/indexes \"Market trends\") *   [AMZN Amazon.com Inc $225.22 +$3.44 1.55% _add\\\\_circle\\\\_outline_](https://www.google.com/finance/beta/quote/quote/AMZN:NASDAQ) *   [F Ford Motor Co $11.74 -$0.18 1.51% _add\\\\_circle\\\\_outline_](https://www.google.com/finance/beta/quote/quote/F:NYSE) *   [TSLA Tesla Inc $438.69 +$5.60 1.29% _add\\\\_circle\\\\_outline_](https://www.google.com/finance/beta/quote/quote/TSLA:NASDAQ) *   [AAPL Apple Inc $258.06 +$1.58 0.62% _add\\\\_circle\\\\_outline_](https://www.google.com/finance/beta/quote/quote/AAPL:NASDAQ) *   [Index S&P 500 6,753.72 +39.13 0.58% _add\\\\_circle\\\\_outline_](https://www.google.com/finance/beta/quote/quote/.INX:INDEXSP) [AMZN 1.55%](https://www.google.com/finance/beta/quote/quote/AMZN:NASDAQ) [_stacked\\\\_line\\\\_chart_ Market indexes](https://www.google.com/finance/beta/quote/markets/indexes)[_equalizer_ Most active](https://www.google.com/finance/beta/quote/markets/most-active)[_trending\\\\_up_ Gainers](https://www.google.com/finance/beta/quote/markets/gainers)[_trending\\\\_down_ Losers](https://www.google.com/finance/beta/quote/markets/losers)[![Image 11: GLeaf logo](https://fonts.gstatic.com/s/i/productlogos/gleaf_dual_tone/v1/192px.svg)Climate leaders](https://www.google.com/finance/beta/quote/markets/climate-leaders)[_copyright_ Crypto](https://www.google.com/finance/beta/quote/markets/cryptocurrencies)[_paid_ Currencies](https://www.google.com/finance/beta/quote/markets/currencies) [More _chevron\\\\_right_](https://www.google.com/finance/beta/quote/markets/most-active) *   [BULL Webull Corp $12.66 1.09% _add\\\\_circle\\\\_outline_](https://www.google.com/finance/beta/quote/quote/BULL:NASDAQ) *   [PLUG Plug Power Inc [Plug Power (PLUG) Stock Slides as Market Rises: Facts to Know Before You Trade Yahoo Finance ‚Ä¢ 4 hours ago](https://finance.yahoo.com/news/plug-power-plug-stock-slides-215002891.html) $3.66 5.56% _add\\\\_circle\\\\_outline_ [Plug Power (PLUG) Stock Slides as Market Rises: Facts to Know Before You Trade Yahoo Finance ‚Ä¢ 4 hours ago](https://finance.yahoo.com/news/plug-power-plug-stock-slides-215002891.html)](https://www.google.com/finance/beta/quote/quote/PLUG:NASDAQ) [View more _navigate\\\\_next_](https://www.google.com/finance/beta/quote/markets/most-active)',\n",
       "  'score': 0.75377536,\n",
       "  'raw_content': None},\n",
       " {'url': 'https://robinhood.com/us/en/stocks/AAPL/',\n",
       "  'title': 'Buy or Sell Apple Stock - AAPL Stock Price Quote & News | Robinhood',\n",
       "  'content': 'Elevate Your Investing Strategy: Take advantage of T...](https://www.tipranks.com/news/weekend-updates/apples-bold-moves-iphone-air-success-f1-deal?utm_source=robinhood.com&utm_medium=referral)[Simply Wall St 19h Apple‚Äôs Advanced AI Hardware Debut and Supply Chain Moves Might Change The Case For Investing In AAPL On October 15, 2025, Apple unveiled its new M5 chip alongside updated versions of the iPad Pro, 14-inch MacBook Pro, and Vision Pro headset, all featuring major... Ivan Lam, an analyst at Counterpoint...](https://www.tipranks.com/news/apples-aapl-new-iphone-air-sold-out-within-minutes-of-launching-in-china?utm_source=robinhood.com&utm_medium=referral)[TipRanks 2d Now Streaming: Apple announces five-year broadcast partnership with F1 ‚ÄúNow Streaming‚Äù is The Fly‚Äôs weekly recap of the stories surrounding the biggest content streamers. ![Image 5: Apple Grabs Exclusive US F1 Rights Starting In 2026](https://images.robinhood.com/Gm1esySIzYGsP_KE7EBV5AlcGMY/aHR0cHM6Ly9jZG4uYmVuemluZ2EuY29tL2ZpbGVzL2ltYWdlcy9zdG9yeS8yMDI1LzEwLzE3L0Zvcm11bGEtMS5qcGVnP3dpZHRoPTEyMDAmaGVpZ2h0PTgwMCZmaXQ9Y3JvcA)](https://www.benzinga.com/markets/equities/25/10/48278541/apple-grabs-exclusive-us-f1-rights-starting-in-2026?utm_source=robinhood.com&utm_campaign=partner_feed&utm_medium=partner_feed&utm_content=ticker_page)[TipRanks 2d Apple Signs Huge Streaming Deal with Formula 1 to Show Races in the U.S. Tech giant Apple (AAPL) and motorsport firm Formula 1 (FWONK) have signed a five-year deal that will make Apple TV the exclusive home for all F1 races in the U....](https://www.tipranks.com/news/apple-aapl-signs-huge-streaming-deal-with-formula-1-to-show-races-in-the-u-s?utm_source=robinhood.com&utm_medium=referral)',\n",
       "  'score': 0.73459625,\n",
       "  'raw_content': None}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "search_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7545f4-aeb7-4b03-91f5-df3e021fe960",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
